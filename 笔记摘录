在redis的服务器中，会至少存在三个队列： 
a.用于请求对象去重的集合，队列的名称为spider.name:dupefilter，其中spider.name就是我们自定义的spider的名字，下同。 
b.待抓取的request对象的有序集合，队列的名称为spider.name:requests 
c.保存提取到item的列表，队列的名称为spider.name:items 
d.可能存在存放初始url的集合或者是列表，队列的名称可能是spider.name:start_urls

内存监控：
MEMUSAGE_NOTIFY_MAIL = ['3081881935@qq.com']
MEMUSAGE_REPORT = True
MEMUSAGE_ENABLED = True
MEMUSAGE_LIMIT_MB = 2048
MEMDEBUG_ENABLED = True
MEMDEBUG_NOTIFY = []

EXTENSIONS = {
    'share_code.extensionsItem.SpiderOpenCloseLogging': 100,
    'share_code.extensionsTime.Latencies': None,
    'scrapy.contrib.memusage.MemoryUsage': 50,
    'scrapy.contrib.memdebug.MemoryDebugger': 60
}

基于形态相似距离的时间序列相似度计算  李中刘洋洋 
https://wenku.baidu.com/view/58dfefbc2b160b4e777fcf77.html


隐藏层大小：（输入大小+输出大小）*2/3

hive -e "select * from /sdbadmin/hadoop/input/900915.csv" >> res1.csv新建csv文件，在此之前先将hdfs数据导入hive。

启动hive：
Service mysqld start
hive --service metastore
hive


scrapy_redis原理

(https://blog.csdn.net/hjhmpl123/article/details/53292602)
scrapy-redis原理: 
1.spider解析下载器下载下来的response,返回item或者是links 
2.item或者links经过spidermiddleware的process_spider_out()方法，交给engine。 
3.engine将item交给itempipeline,将links交给调度器 
4.在调度器中，先将request对象利用scrapy内置的指纹函数，生成一个指纹对象 
5.如果request对象中的dont_filter参数设置为False,并且该request对象的指纹不在信息指纹的队列中，那么就把该request对象放到优先级的队列中 
6.从优先级队列中获取request对象，交给engine 
7.engine将request对象交给下载器下载，期间会通过downloadmiddleware的process_request()方法 
8.下载器完成下载，获得response对象，将该对象交给engine,期间会通过downloadmiddleware的process_response()方法 
9.engine将获得的response对象交给spider进行解析，期间会经过spidermiddleware的process_spider_input()方法 
10.从第一步开始循环
